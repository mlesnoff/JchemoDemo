---
title: gridscore_plsrda_forages2.jl
weave_options:
  error: true
  wrap: true
  term: false
  #out_width: "50%"   # default
---

```julia
using JLD2, CairoMakie, FreqTables, StatsBase 
using Jchemo, JchemoData
```

#### Data importation

```julia
path_jdat = dirname(dirname(pathof(JchemoData)))
db = joinpath(path_jdat, "data/forages2.jld2") 
@load db dat
pnames(dat)
```
  
#### Data preparation and short description

```julia
X = dat.X 
Y = dat.Y
ntot = nro(X)
```

```julia term = true
@head X
@head Y
```

```julia
y = Y.typ
tab(y)
```

```julia
freqtable(y, Y.test)
```

```julia
wl = names(X)
wl_num = parse.(Float64, wl)
```

**Note:**: X-data are already preprocessed (SNV + Savitsky-Golay).

```julia
plotsp(X, wl_num;
    xlabel = "Wavelength (nm)", ylabel = "Absorbance").f
```

#### Split Tot ==> Train + Test

The model is tuned on **Train**, and the generalization error is estimated on **Test**.
Here the split of **Tot** is already provided inside the dataset (= variable `test`), 
but **Tot** could also be split *a posteriori*, for instance by sampling (random, systematic 
or any other designs). 

```julia
s = Bool.(Y.test)
Xtrain = rmrow(X, s)
ytrain = rmrow(y, s)
Xtest = X[s, :]
ytest = y[s]
ntrain = nro(Xtrain)
ntest = nro(Xtest)
(ntot = ntot, ntrain, ntest)
```

#### Split Train ==> Cal + Val

The validation error (used for the grid-search tuning) is computed 
on **Val**. Below the split is built from a random sampling 
(other designs are possible).

```julia
pct = .30
nval = Int64.(round(pct * ntrain))
ncal = ntrain - nval 
s = sample(1:ntrain, nval; replace = false)
Xcal = rmrow(Xtrain, s) 
ycal = rmrow(ytrain, s) 
Xval = Xtrain[s, :] 
yval = ytrain[s] 
(ntot = ntot, ntrain, ntest, ncal, nval)
```

#### Grid-search

```julia
nlv = 0:50
res = gridscorelv(Xcal, ycal, Xval, yval; 
    score = err, fun = plsrda, nlv = nlv)
```

**Selection of the best parameters combination:**

```julia
plotgrid(res.nlv, res.y1; step = 5,
    xlabel = "Nb. LVs", ylabel = "ERR").f
```

```julia
u = findall(res.y1 .== minimum(res.y1))[1] 
res[u, :]
```

#### Final prediction (Test) using the optimal model

```julia
fm = plsrda(Xtrain, ytrain; nlv = res.nlv[u]) ;
pred = Jchemo.predict(fm, Xtest).pred
```

#### Generalization error

```julia
err(pred, ytest)
```

#### Confusion matrix

```julia
cf = confusion(pred, ytest) ;
pnames(cf)
```

```julia
cf.cnt
```

```julia
cf.pct
```

```julia
cf.accuracy 
```

```julia
plotconf(cf).f
```
