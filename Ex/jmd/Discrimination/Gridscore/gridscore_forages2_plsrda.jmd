---
title: gridscore - forages2 - Plsrda 
weave_options:
  error: true
  wrap: true
  term: false
  out_width: 60%
  out_height: 30%
---

```julia term = true
using Jchemo, JchemoData
using JLD2, CairoMakie
using FreqTables 
```

#### Data importation

```julia term = true
path_jdat = dirname(dirname(pathof(JchemoData)))
db = joinpath(path_jdat, "data/forages2.jld2") 
@load db dat
@names dat
```

```julia term = true
X = dat.X 
Y = dat.Y
ntot = nro(X)
y = Y.typ ;
test = Y.test ;
tab(y)
```

```julia term = true
freqtable(y, test)
```

```julia term = true
wlst = names(X)
wl = parse.(Int, wlst) ;
#plotsp(X, wl; xlabel = "Wavelength (nm)", ylabel = "Absorbance").f
```

**Note:**: X-data are already preprocessed (SNV + Savitsky-Golay 2nd deriv).

#### Split Tot to Train/Test

The model is fitted on **Train**, and the generalization error is estimated on **Test**.
In this example, **Train** is already defined in variable `typ` of the dataset, and **Test** is defined by the remaining 
samples. But **Tot** could also be split *a posteriori*, for instance by sampling (random, systematic or any other designs). 
See for instance functions `samprand`, `sampsys`, etc.

```julia term = true
s = Bool.(test) ;
Xtrain = rmrow(X, s) ;
ytrain = rmrow(y, s) ;
Xtest = X[s, :] ;
ytest = y[s] ;
ntrain = nro(Xtrain)
ntest = nro(Xtest)
(ntot = ntot, ntrain, ntest)
```

```julia term = true
tab(ytrain)
tab(ytest)
```

#### Split Train to Cal/Val for model tuning

The training set (**Train**) is split to a calibration set (**Cal**) and a validation set (**Val**). 
A grid search is implemented by fitting the model on **Cal** and computing a validation error on **Val**.   

The split Cal/Val can be built from different sampling designs. Below, a random sampling is used.

```julia term = true
pct = .3  # proportion of Train for Val
nval = round(Int, pct * ntrain)    
s = samprand(ntrain, nval)
```

```julia term = true
Xcal = Xtrain[s.train, :] ;
ycal = ytrain[s.train] ;
Xval = Xtrain[s.test, :] ;
yval = ytrain[s.test] ;
ncal = ntrain - nval 
(ntot = ntot, ntrain, ncal, nval, ntest)
```

#### Grid-search 

```julia term = true
nlv = 0:20
model = plsrda()
res = gridscore(model, Xcal, ycal, Xval, yval; score = errp, nlv) 
```

```julia term = true
plotgrid(res.nlv, res.y1; step = 2, xlabel = "Nb. LVs", ylabel = "ERRP-Val").f
```

If other parameters have to be defined in the grid, they have to be set in argument `pars`, such as in 
the example below. 

The importance of each class is made equal (recommended if classes are highly unbalnaced) and a X-scaling 
is evaluated. 

```julia term = true
pars = mpar(prior = [:unif], scal = [false; true])
nlv = 0:20
model = plsrda()
res = gridscore(model, Xcal, ycal, Xval, yval; score = merrp, pars, nlv)
```

```julia term = true
group = string.("prior=", res.prior, " scal=", res.scal)
plotgrid(res.nlv, res.y1, group; step = 2, xlabel = "Nb. LVs", ylabel = "ERRP-Val").f
```

**Selection of the best parameter combination**

```julia term = true
u = findall(res.y1 .== minimum(res.y1))[1] 
res[u, :]
```

#### Final prediction (Test) using the optimal model

```julia term = true
model = plsrda(prior = res.prior[u], nlv = res.nlv[u], scal = res.scal[u])
fit!(model, Xtrain, ytrain)
pred = predict(model, Xtest).pred
```

**Generalization error**

```julia term = true
errp(pred, ytest)
merrp(pred, ytest)
```

```julia term = true
cf = conf(pred, ytest) ;
@names cf
cf.cnt
cf.pct
```
