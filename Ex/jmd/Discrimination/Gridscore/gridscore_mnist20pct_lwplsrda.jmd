---
title: gridscore - mnistpct20 - kNN-Lwplsrda 
weave_options:
  error: true
  wrap: false
  term: false
  out_width: 60%
  out_height: 30%
---

```julia
using Jchemo, JchemoData
using JLD2, CairoMakie
using FreqTables 
```

#### Data importation

```julia
path_jdat = dirname(dirname(pathof(JchemoData)))
db = joinpath(path_jdat, "data/mnist20pct.jld2") 
@load db dat
@names dat
```

```julia
Xtrain = dat.Xtrain
ytrain = dat.ytrain
Xtest = dat.Xtest
ytest = dat.ytest
@head Xtrain
@head Xtest
tab(ytrain)
tab(ytest)
ntrain, p = size(Xtrain)
ntest = nro(Xtest)
ntot = ntrain + ntest
(ntot = ntot, ntrain, ntest)  
```

Grey levels 0-255 standardized between 0-1 (not required here but used when fitting deep learning models)

```julia
Xtrain = Matrix(Xtrain) / 255
Xtest = Matrix(Xtest) / 255
```
Example of one sample (= one unfolded image)

```julia
plotsp(Xtrain, 1:p; nsamp = 1, xlabel = "Pixel", ylabel = "Grey level").f
```

#### Split Train to Cal/Val for model tuning

Below, Cal and Val are built by random sampling (other designs could be used)

```julia
nval = 1000
nval / ntrain # sampling proportion 
s = samprand(ntrain, nval)
```

```julia
Xcal = Xtrain[s.train, :]
ycal = ytrain[s.train]
Xval = Xtrain[s.test, :]
yval = ytrain[s.test]
ncal = ntrain - nval 
(ntot = ntot, ntrain, ncal, nval, ntest)
```

#### Grid-search 

```julia
nlvdis = [10; 20]; metric = [:mah]
h = [1; 2; 5; Inf]; k = [200; 300; 500; 1000]  
nlv = 0:15
pars = mpar(nlvdis = nlvdis, metric = metric, h = h, k = k) 
length(pars[1])
```

```julia
model = lwplsrda()
res = gridscore(model, Xcal, ycal, Xval, yval; score = errp, pars, nlv)   
```

```julia
group = string.("nvldis=", res.nlvdis, " h=", res.h, " k=", res.k)
plotgrid(res.nlv, res.y1, group; step = 2, xlabel = "Nb. LVs", ylabel = "ERRP-Val").f
```

**Selection of the best parameter combination**

```julia
u = findall(res.y1 .== minimum(res.y1))[1] 
res[u, :]
```

#### Final prediction (Test) using the optimal model

```julia
model = lwplsrda(nlvdis = res.nlvdis[u], metric = res.metric[u], h = res.h[u], 
    k = res.k[u], nlv = res.nlv[u])
fit!(model, Xtrain, ytrain)
@head pred = predict(model, Xtest).pred
```

**Generalization error**

```julia
errp(pred, ytest)
```

```julia
merrp(pred, ytest)
```

```julia
cf = conf(pred, ytest)
@names cf
```

```julia
cf.cnt
```

```julia
cf.pct
```

```julia
plotconf(cf).f
```

```julia
plotconf(cf; cnt = false).f
```
