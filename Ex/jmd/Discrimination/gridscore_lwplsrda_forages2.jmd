---
title: gridscore_lwplsrda_forages2.jl
weave_options:
  error: true
  wrap: true
  term: false
  #out_width: "50%"   # default
---

```julia
using Jchemo, JchemoData
using JLD2, CairoMakie, FreqTables
```

#### Data importation

```julia
path_jdat = dirname(dirname(pathof(JchemoData)))
db = joinpath(path_jdat, "data/forages2.jld2") 
@load db dat
pnames(dat)
```
  
#### Data preparation and short description

```julia
X = dat.X 
Y = dat.Y
ntot = nro(X)
```

```julia term = true
@head X
@head Y
```

```julia
y = Y.typ
tab(y)
```

```julia
freqtable(y, Y.test)
```

```julia
wlst = names(X)
wl = parse.(Float64, wlst) 
```

**Note:**: X-data are already preprocessed (SNV + Savitsky-Golay).

```julia
plotsp(X, wl; xlabel = "Wavelength (nm)", ylabel = "Absorbance").f
```

#### Split Tot ==> Train + Test

The model is fitted on **Train**, and the generalization error is estimated on **Test**.
Here the split of **Tot** is already provided inside the dataset (= variable `test`), 
but **Tot** could also be split *a posteriori*, for instance by sampling (random, systematic 
or any other designs). 

```julia
s = Bool.(Y.test)
Xtrain = rmrow(X, s)
ytrain = rmrow(y, s)
Xtest = X[s, :]
ytest = y[s]
ntrain = nro(Xtrain)
ntest = nro(Xtest)
(ntot = ntot, ntrain, ntest)
```

#### Split Train ==> Cal + Val

The validation error (used for the grid-search tuning) is computed 
on **Val**. Below the split is built from a random sampling 
(other designs are possible).

```julia
pct = .30
nval = Int64.(round(pct * ntrain))
s = samprand(ntrain, nval)
Xcal = Xtrain[s.train, :]
ycal = ytrain[s.train]
Xval = Xtrain[s.test, :]
yval = ytrain[s.test]
ncal = ntrain - nval 
(ntot = ntot, ntrain, ntest, ncal, nval)
```

#### Grid

```julia
nlvdis = [15; 25] ; metric = [:mah]
h = [1; 2; 5] ; k = [100; 200; 300]
nlv = 0:15
pars = mpar(nlvdis = nlvdis, metric = metric, h = h, k = k)
```

```julia
length(pars[1])
```

#### Grid-search

```julia
mod = lwplsrda()
res = gridscore(mod, Xcal, ycal, Xval, yval; score = errp, nlv, pars, verbose = false)
```

**Selection of the best parameters combination:**

```julia
group = string.("metric=", res.metric, res.nlvdis, " h=", res.h, " k=", res.k)
plotgrid(res.nlv, res.y1, group; step = 2, xlabel = "Nb. LVs", ylabel = "ERR").f
```

```julia
u = findall(res.y1 .== minimum(res.y1))[1] 
res[u, :]
```

#### Final prediction (Test) using the optimal model

```julia
mod = lwplsrda(nlvdis = res.nlvdis[u], metric = res.metric[u], 
    h = res.h[u], k = res.k[u], nlv = res.nlv[u], verbose = false) ;
fit!(mod, Xtrain, ytrain)
pred = predict(mod, Xtest).pred
```

#### Generalization error

```julia
errp(pred, ytest)
```

#### Confusion matrix

```julia
cf = conf(pred, ytest) ;
pnames(cf)
```

```julia
cf.cnt
```

```julia
cf.pct
```

```julia
cf.diagpct
```

```julia
cf.accpct
```

```julia
plotconf(cf).f
```
