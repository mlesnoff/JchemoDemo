---
title: gridscore_lwplsravg_challenge2018.jl
weave_options:
  error: true
  wrap: true
  term: false
  #out_width: "50%"   # default
---

```julia
using Jchemo, JchemoData
using JLD2, CairoMakie
using FreqTables
```

#### Data importation

```julia
path_jdat = dirname(dirname(pathof(JchemoData)))
db = joinpath(path_jdat, "data/challenge2018.jld2") 
@load db dat
pnames(dat)
```

#### Data preparation and short description

```julia
X = dat.X 
Y = dat.Y
ntot, p = size(X)
```

```julia term = true
@head X
@head Y
```

```julia
summ(Y)
```

```julia
y = Y.conc
typ = Y.typ
label = Y.label 
test = Y.test
tab(test)
```

```julia
wlst = names(X)
wl = parse.(Float64, wlst) 
```

```julia
freqtable(string.(typ, "-", Y.label))
```

```julia
freqtable(typ, test)
```

```julia
plotsp(X, wl; nsamp = 30).f
```

#### Preprocessing

```julia
mod1 = model(snv; centr = true, scal = true)
mod2 = model(savgol; npoint = 21, deriv = 2, degree = 3)
mod = pip(mod1, mod2)
fit!(mod, X)
Xp = transf(mod, X) 
```

```julia
plotsp(Xp, wl; nsamp = 30).f
```

#### Split Tot ==> Train + Test

The model is tuned on **Train**, and the generalization error is estimated on **Test**.
Here the split of **Tot** is already provided inside the dataset (= variable `test`), 
but **Tot** could also be split *a posteriori*, for instance by sampling (random, systematic 
or any other designs). 

```julia
s = Bool.(test)
Xtrain = rmrow(Xp, s)
ytrain = rmrow(y, s)
Xtest = Xp[s, :]
ytest = y[s]
ntrain = nro(Xtrain)
ntest = nro(Xtest)
(ntot = ntot, ntrain, ntest)
```

#### Split Train ==> Cal + Val

The validation error (used for the grid-search tuning) is computed 
on **Val**. Here the split is built from random sampling 
(other designs are possible).

```julia
nval = 300
s = samprand(ntrain, nval)
Xcal = Xtrain[s.train, :]
ycal = ytrain[s.train]
Xval = Xtrain[s.test, :]
yval = ytrain[s.test]
ncal = ntrain - nval 
(ntot = ntot, ntrain, ntest, ncal, nval)
```

#### Grid

```julia
nlvdis = [15; 25] ; metric = [:mah] 
h = [1; 2; 4] ; k = [150; 200; 350; 500]  
nlv = [0:20, 5:20, 10:20]
pars = mpar(nlvdis = nlvdis, metric = metric, h = h, k = k, nlv = nlv) 
```

```julia
length(pars[1])
```

#### Grid-search

```julia
mod = model(lwplsravg)
res = gridscore(mod, Xcal, ycal, Xval, yval; score = rmsep, pars, verbose = false) 
```

**Selection of the best parameters combination:**

```julia
u = findall(res.y1 .== minimum(res.y1))[1] 
res[u, :]
```

#### Final prediction (Test) using the optimal model

```julia
mod = model(lwplsravg; nlvdis = res.nlvdis[u], metric = res.metric[u], h = res.h[u], 
    k = res.k[u], nlv = res.nlv[u]) ;
fit!(mod, Xtrain, ytrain) 
pred = predict(mod, Xtest).pred 
rmsep(pred, ytest)
```

```julia
plotxy(pred, ytest; color = (:red, .5), bisect = true, xlabel = "Prediction", 
    ylabel = "Observed (Test)").f  
```

