---
title: gridscore_lwplsr_challenge2018.jl
weave_options:
  error: true
  wrap: true
  term: false
  #out_width: "50%"   # default
---

```julia
using JLD2, CairoMakie, StatsBase
using Jchemo, JchemoData
using FreqTables
```

#### Data importation

```julia
path_jdat = dirname(dirname(pathof(JchemoData)))
db = joinpath(path_jdat, "data/challenge2018.jld2") 
@load db dat
pnames(dat)
```

#### Data preparation and short description

```julia
X = dat.X 
Y = dat.Y
ntot, p = size(X)
```

```julia term = true
@head X
@head Y
```

```julia
summ(Y)
```

```julia
y = Y.conc
typ = Y.typ
label = Y.label 
test = Y.test
tab(test)
```

```julia
wl = names(X)
wl_num = parse.(Float64, wl)
```

```julia
freqtable(string.(typ, "-", Y.label))
```

```julia
freqtable(typ, test)
```

```julia
plotsp(X, wl_num; nsamp = 30).f
```

#### Preprocessing

```julia
f = 21 ; pol = 3 ; d = 2 
Xp = savgol(snv(X); f = f, pol = pol, d = d) ;
```

``` julia
plotsp(Xp, wl_num; nsamp = 30).f
```

#### Split Tot ==> Train + Test

The model is tuned on **Train**, and the generalization error is estimated on **Test**.
Here the split of **Tot** is already provided inside the dataset (= variable `test`), 
but **Tot** could also be split *a posteriori*, for instance by sampling (random, systematic 
or any other designs). 

```julia
s = Bool.(test)
Xtrain = rmrow(Xp, s)
ytrain = rmrow(y, s)
Xtest = Xp[s, :]
ytest = y[s]
ntrain = nro(Xtrain)
ntest = nro(Xtest)
(ntot = ntot, ntrain, ntest)
```

#### Split Train ==> Cal + Val

The validation error (used for the grid-search tuning) is computed 
on **Val**. The split can be built from different sampling designs,
as below (other designs are possible).

```julia
nval = 300
## Or:
#pct = .20
#nval = Int64(round(pct * ntrain))    
```

- (1) Random sampling:

```julia
s = sample(1:ntrain, nval; replace = false)
```

- (2) Or  Kennard-Stone sampling (output 'train' contains higher variability 
    than output `test`):

```julia
#res = sampks(Xtrain; k = nval)
#s = res.train
```

- (3) Or duplex sampling:

```julia
#res = sampdp(Xtrain; k = nval)
#s = res.train
```

- (4) Or systematic sampling over `y`:

```julia
#res = sampsys(ytrain; k = nval)
#s = res.train
```

```julia
Xcal = rmrow(Xtrain, s)
ycal = rmrow(ytrain, s)
Xval = Xtrain[s, :]
yval = ytrain[s, :]
ncal = ntrain - nval 
(ntot = ntot, ntrain, ntest, ncal, nval)
```

#### Grid-search

```julia
nlv = 0:50
res = gridscorelv(Xcal, ycal, Xval, yval; 
    score = rmsep, fun = plskern, nlv = nlv) 
```

**Selection of the best parameters combination:**

```julia
plotgrid(res.nlv, res.y1; step = 5,
    xlabel = "Nb. LVs", ylabel = "RMSEP").f
```

```julia
u = findall(res.y1 .== minimum(res.y1))[1] 
res[u, :]
```

#### Final prediction (Test) using the optimal model

```julia
fm = plskern(Xtrain, ytrain; nlv = res.nlv[u]) ;
pred = Jchemo.predict(fm, Xtest).pred
```

#### Generalization error

```julia
rmsep(pred, ytest)
```

```julia 
plotxy(pred, ytest; color = (:red, .5),
    bisect = true, xlabel = "Prediction", 
    ylabel = "Observed (Test)").f
```

#### A parcimony approach Wold's criterion

```julia
res_sel = selwold(res.nlv, res.y1; smooth = false, 
    alpha = .05, graph = true) ;
pnames(res)
```

```julia
res_sel.f       # plots
```

```julia
res_sel.opt     # nb. LVs correponding to the minimal error rate
```

```julia
res_sel.sel     # nb. LVs selected with the Wold's criterion
```

**Final prediction with the parcimonious model:**

```julia
fm = plskern(Xtrain, ytrain; nlv = res_sel.sel) ;
pred = Jchemo.predict(fm, Xtest).pred
rmsep(pred, ytest)
```

#### Remark

Function "gridscore" is generic for all the functions.
Here, it could be used instead of "gridscorelv" 
but this is not time-efficient for LV-based methods.
Commands below return the same results as 
with 'gridscorelv', but in a slower way.

```julia
nlv = 0:50
pars = mpar(nlv = nlv)
res = gridscore(Xcal, ycal, Xval, yval;  
    score = rmsep, fun = plskern, pars = pars) 
u = findall(res.y1 .== minimum(res.y1))[1] 
res[u, :]
```


