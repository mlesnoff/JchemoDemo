---
title: lwmlr_s_cassav.jl
weave_options:
  error: true
  wrap: true
  term: false
  #out_width: "50%"   # default
---

```julia
using Jchemo, JchemoData
using JLD2, CairoMakie
```

#### Data importation

```julia
using JchemoData, JLD2, CairoMakie
path_jdat = dirname(dirname(pathof(JchemoData)))
db = joinpath(path_jdat, "data/cassav.jld2")
@load db dat
pnames(dat)
```

#### Data preparation and short description

```julia
X = dat.X
Y = dat.Y
ntot = nro(X)
```

```julia term = true
@head X
@head Y
```

```julia
y = dat.Y.tbc
year = dat.Y.year
```

```julia
tab(year)
```

```julia
wlst = names(X)
wl = parse.(Float64, wlst) 
```

```julia
plotsp(X, wl; xlabel = "Wavelength (nm)", ylabel = "Absorbance").f
```

#### Preprocessing

```julia
model1 = snv)
model2 = savgol; npoint = 11, deriv = 2, degree = 3)
model = pip(model1, model2)
fit!(model, X)
Xp = transf(model, X) 
```

```julia
plotsp(Xp, wl; xlabel = "Wavelength (nm)", ylabel = "Absorbance").f
```

#### Split Tot ==> Train + Test

The model is fitted on **Train**, and the generalization error is estimated on **Test**.
Here the split of **Tot** is already provided inside the dataset (= variable `year`), 
but **Tot** could also be split *a posteriori*, for instance by sampling (random, systematic 
or any other designs). 

```julia
s = year .<= 2012
Xtrain = X[s, :]
ytrain = y[s]
Xtest = rmrow(X, s)
ytest = rmrow(y, s)
ntrain = nro(Xtrain)
ntest = nro(Xtest)
ntot = ntrain + ntest
(ntot = ntot, ntrain, ntest)
```

```julia
plotsp(X, wl; xlabel = "Wavelength (nm)", ylabel = "Absorbance").f
```

#### Split Train ==> Cal + Val

The validation error (used for the grid-search tuning) is computed 
on **Val**. The split can be built from different sampling designs,
as below (other designs are possible).

```julia
nval = Int64(round(.30 * ntrain))
s = sampsys(ytrain, nval)
Xcal = Xtrain[s.train, :]
ycal = ytrain[s.train]
Xval = Xtrain[s.test, :]
yval = ytrain[s.test, :]
ncal = ntrain - nval
(ntot = ntot, ntrain, ntest, ncal, nval)
```

#### Benchmark with PLSR

```julia
model = plskern)
nlv = 0:40
res = gridscore(model, Xcal, ycal, Xval, yval; score = rmsep, nlv) 
```

```julia
plotgrid(res.nlv, res.y1; step = 5, xlabel = "Nb. LVs", ylabel = "RMSEP").f
```

```julia
u = findall(res.y1 .== minimum(res.y1))[1] 
res[u, :]
```

```julia
model = plskern; nlv = res.nlv[u]) 
fit!(model, Xtrain, ytrain)
pred = predict(model, Xtest).pred 
rmsep(pred, ytest)
mse(pred, ytest)
```

```julia
plotxy(pred, ytest; color = (:red, .5), bisect = true, xlabel = "Prediction", 
  ylabel = "Observed (Test)").f
```

#### LWMLR on preliminary PCA scores
#### = "LWR" algorithm of Naes et al. 1990

```julia
nlv = 15
metric = [:eucl, :mah]
h = [1; 2; 3.5; 6] ; k = [50; 100; 150; 200]  
pars = mpar(metric = metric, h = h, k = k) 
length(pars[1])
```

```julia
model1 = pcasvd)
model2 = lwmlr)
model = pip(model1, model2)
res = gridscore(model, Xcal, ycal, Xval, yval; score = rmsep, pars, verbose = false) 
```

```julia
u = findall(res.y1 .== minimum(res.y1))[1] 
res[u, :]
```

```julia
model1 = pcasvd; nlv)
model2 = lwmlr; metric = res.metric[u], h = res.h[u], k = res.k[u])
model = pip(model1, model2)
fit!(model, Xtrain, ytrain)
pred = predict(model, Xtest).pred
@show rmsep(pred, ytest)
mse(pred, ytest)
```

```julia
plotxy(pred, ytest; color = (:red, .5), bisect = true, xlabel = "Prediction", 
    ylabel = "Observed (Test)").f
```

#### LWMLR on preliminary PLS scores

```julia
nlv = 15
metric = [:eucl, :mah]
h = [1; 2; 3.5; 6] ; k = [50; 100; 150; 200]  
pars = mpar(metric = metric, h = h, k = k) 
length(pars[1])
```

```julia
model1 = plskern)
model2 = lwmlr)
model = pip(model1, model2)
## Pipeline ==> only the last model is tuned
res = gridscore(model, Xcal, ycal, Xval, yval; score = rmsep, pars, verbose = false) 
```

```julia
u = findall(res.y1 .== minimum(res.y1))[1] 
res[u, :]
```

```julia
model1 = plskern; nlv)
model2 = lwmlr; metric = res.metric[u], h = res.h[u], k = res.k[u])
model = pip(model1, model2)
fit!(model, Xtrain, ytrain)
pred = predict(model, Xtest).pred
@show rmsep(pred, ytest)
mse(pred, ytest)
```

```julia
plotxy(pred, ytest; color = (:red, .5), bisect = true, xlabel = "Prediction", 
    ylabel = "Observed (Test)").f
```

#### LWMLR on preliminary DKPLS scores

```julia
nlv = 15 ; gamma = .01
metric = [:eucl, :mah]
h = [1; 2; 3.5; 6] ; k = [50; 100; 150; 200]  
pars = mpar(metric = metric, h = h, k = k) 
length(pars[1])
```

```julia
model1 = dkplsr)
model2 = lwmlr)
model = pip(model1, model2)
res = gridscore(model, Xcal, ycal, Xval, yval; score = rmsep, pars, verbose = false) 
```

```julia
u = findall(res.y1 .== minimum(res.y1))[1] 
res[u, :]
```

```julia
model1 = dkplsr; nlv, gamma)
model2 = lwmlr; metric = res.metric[u], h = res.h[u], k = res.k[u])
model = pip(model1, model2)
fit!(model, Xtrain, ytrain)
pred = predict(model, Xtest).pred
@show rmsep(pred, ytest)
mse(pred, ytest)
```

```julia
plotxy(pred, ytest; color = (:red, .5), bisect = true, xlabel = "Prediction", 
    ylabel = "Observed (Test)").f
```
